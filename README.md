# ğŸ“„ Web-Scraping-Project

A simple web scraping project built for educational purposes.  
It demonstrates how to extract content from a website and save the data into various formats including CSV, PDF, HTML, JPG, and TXT.

---

## ğŸ“š About

This project was created as part of a **college assignment** to practice **web scraping** and **data extraction** using Python.  
It includes:
- A Python script (`scrab.py`) that performs the scraping.
- Output files demonstrating different formats:
  - `.csv` for structured tabular data
  - `.pdf` for document-style output
  - `.html` for saving the web page structure
  - `.jpg` for saving images
  - `.txt` for plain text extraction

Built using:
- **Python 3**
- **BeautifulSoup4**
- **Requests**
- **Pandas** (for CSV handling)
- **fpdf** or similar library (for PDF generation)

---

## ğŸ—‚ï¸ Project Structure

| File                 | Purpose                                |
|----------------------|----------------------------------------|
| `scrab.py`           | Main Python script for web scraping    |
| `scraped_data.csv`   | Output of scraped data in CSV format   |
| `scraped_document.pdf` | Output of scraped data in PDF format |
| `scraped_html.html`  | Full saved HTML of the scraped page    |
| `scraped_image.jpg`  | Example of an image extracted          |
| `scraped_text.txt`   | Plain text extracted from the page     |

---

## ğŸš€ How to Run the Project

1. **Clone the repository**

   ğŸ‘‰ [GitHub Repository Link](https://github.com/Noursalem2005/Web-Scraping-Project)

   ```bash
   git clone https://github.com/Noursalem2005/Web-Scraping-Project.git
   cd Web-Scraping-Project
